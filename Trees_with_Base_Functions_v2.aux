\relax 
\providecommand\hyper@newdestlabel[2]{}
\bibstyle{elsarticle-harv}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\emailauthor{paezha@mcmaster.ca}{Antonio Paez\corref {c1}}
\emailauthor{fernando.lopez@upct.es}{Fernando Lopez}
\emailauthor{manuel.ruiz@upct.es}{Manuel Ruiz}
\emailauthor{m.camacho@um.es}{Maximo Camacho}
\Newlabel{c1}{1}
\Newlabel{McMaster University}{a}
\Newlabel{Universidad Politecnica de Cartagena}{b}
\Newlabel{Universidad de Murcia}{c}
\@writefile{toc}{\contentsline {section}{1 Introduction}{2}{section*.1}}
\newlabel{introduction}{{}{2}{1 Introduction}{section*.1}{}}
\@writefile{toc}{\contentsline {section}{2 Background}{3}{section*.2}}
\newlabel{background}{{}{3}{2 Background}{section*.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Prototypical Decision Tree}}{4}{figure.1}}
\newlabel{fig:fig1-example}{{1}{4}{Prototypical Decision Tree}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Chessboard example with variable Y with two classes}}{5}{figure.2}}
\newlabel{fig:fig2-chessboard}{{2}{5}{Chessboard example with variable Y with two classes}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{3 Interactive Basis Functions (IBFs)}{6}{section*.3}}
\newlabel{interactive-basis-functions-ibfs}{{}{6}{3 Interactive Basis Functions (IBFs)}{section*.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Example of a basis function used as a feature to train a Decision Tree to classify variable Y with two classes}}{7}{figure.3}}
\newlabel{fig:fig3-simple-basis}{{3}{7}{Example of a basis function used as a feature to train a Decision Tree to classify variable Y with two classes}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Oblique basis function and projections with different splitting points (s)}}{8}{figure.4}}
\newlabel{fig:fig4-additive-basis}{{4}{8}{Oblique basis function and projections with different splitting points (s)}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Hyperbolic basis function and projections with different splitting points (s)}}{9}{figure.5}}
\newlabel{fig:fig5-hyperbolic-basis}{{5}{9}{Hyperbolic basis function and projections with different splitting points (s)}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Radial IBF and projections with different splitting points (s)}}{10}{figure.6}}
\newlabel{fig:fig6-radial-basis}{{6}{10}{Radial IBF and projections with different splitting points (s)}{figure.6}{}}
\@writefile{toc}{\contentsline {section}{4 Practical Considerations}{10}{section*.4}}
\newlabel{practical-considerations}{{}{10}{4 Practical Considerations}{section*.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Behavior of radial IBF with non-centered/non-scaled variables (top panel) and centered/scaled variables (bottom panel)}}{11}{figure.7}}
\newlabel{fig:fig7-curvature}{{7}{11}{Behavior of radial IBF with non-centered/non-scaled variables (top panel) and centered/scaled variables (bottom panel)}{figure.7}{}}
\@writefile{toc}{\contentsline {section}{5 Benchmarking}{11}{section*.5}}
\newlabel{benchmarking}{{}{11}{5 Benchmarking}{section*.5}{}}
\newlabel{tab:dataset-description}{{1}{12}{5 Benchmarking}{table.1}{}}
\newlabel{tab:Datasets}{{1}{12}{5 Benchmarking}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{Datasets for Benchmarking Experiment}}{12}{table.1}}
\newlabel{tab:Datasets}{{1}{13}{5 Benchmarking}{table.1}{}}
\gdef \LT@i {\LT@entry 
    {1}{45.80602pt}\LT@entry 
    {6}{161.77773pt}\LT@entry 
    {1}{68.52832pt}\LT@entry 
    {1}{48.88931pt}\LT@entry 
    {1}{43.27773pt}\LT@entry 
    {1}{95.36098pt}}
\newlabel{tab:Datasets}{{1}{14}{5 Benchmarking}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Summary of Benchmarking Experiment}}{15}{table.2}}
\newlabel{tab:summary}{{2}{15}{Summary of Benchmarking Experiment}{table.2}{}}
\newlabel{tab:summary-benchmarking}{{2}{15}{Summary of Benchmarking Experiment}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{5.1 Accuracy}{16}{section*.6}}
\newlabel{accuracy}{{}{16}{5.1 Accuracy}{section*.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Benchmarking results: Classification accuracy by Algorithm}}{17}{figure.8}}
\newlabel{fig:fig8-performance-algorithm-results}{{8}{17}{Benchmarking results: Classification accuracy by Algorithm}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Accuracy comparison for method tree: orthogonal and IBF implementations}}{18}{figure.9}}
\newlabel{fig:fig9-accuracy-tree}{{9}{18}{Accuracy comparison for method tree: orthogonal and IBF implementations}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Accuracy comparison for method random forest: orthogonal and IBF implementations}}{19}{figure.10}}
\newlabel{fig:fig10-accuracy-forest}{{10}{19}{Accuracy comparison for method random forest: orthogonal and IBF implementations}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Accuracy comparison for method evolutionary tree: orthogonal and IBF implementations}}{20}{figure.11}}
\newlabel{fig:fig11-accuracy-ev}{{11}{20}{Accuracy comparison for method evolutionary tree: orthogonal and IBF implementations}{figure.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Accuracy: Results of logistic model (dependent variable: proportion of correct predictions)}}{22}{table.3}}
\newlabel{tab:model-accuracy-results}{{3}{22}{Accuracy: Results of logistic model (dependent variable: proportion of correct predictions)}{table.3}{}}
\newlabel{tab:model-accuracy-results}{{3}{22}{Accuracy: Results of logistic model (dependent variable: proportion of correct predictions)}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{5.2 Tree Size}{23}{section*.7}}
\newlabel{tree-size}{{}{23}{5.2 Tree Size}{section*.7}{}}
\@writefile{toc}{\contentsline {section}{6 Sample Applications}{23}{section*.8}}
\newlabel{sample-applications}{{}{23}{6 Sample Applications}{section*.8}{}}
\@writefile{toc}{\contentsline {subsection}{6.1 Classification Example: Ethnic Neighborhoods}{23}{section*.9}}
\newlabel{classification-example-ethnic-neighborhoods}{{}{23}{6.1 Classification Example: Ethnic Neighborhoods}{section*.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Probability of correctly predicting an observations as a function of number of observations (n)}}{24}{figure.12}}
\newlabel{fig:fig12-estimated-accuracy-n}{{12}{24}{Probability of correctly predicting an observations as a function of number of observations (n)}{figure.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Probability of correctly predicting an observations as a function of number of features (f)}}{25}{figure.13}}
\newlabel{fig:fig13-estimated-accuracy-f}{{13}{25}{Probability of correctly predicting an observations as a function of number of features (f)}{figure.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Probability of correctly predicting an observations as a function of number of classes (k)}}{26}{figure.14}}
\newlabel{fig:fig14-estimated-accuracy-k}{{14}{26}{Probability of correctly predicting an observations as a function of number of classes (k)}{figure.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Probability of correctly predicting an observations as a function of proportion majority class (m)}}{27}{figure.15}}
\newlabel{fig:fig15-estimated-accuracy-m}{{15}{27}{Probability of correctly predicting an observations as a function of proportion majority class (m)}{figure.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Tree size: Results of linear regression model (dependent variable: tree size)}}{28}{table.4}}
\newlabel{tab:model-tree-results}{{4}{28}{Tree size: Results of linear regression model (dependent variable: tree size)}{table.4}{}}
\newlabel{tab:model-tree-results}{{4}{28}{Tree size: Results of linear regression model (dependent variable: tree size)}{table.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Three ethnic groups in Newark (1880 US Census)}}{29}{figure.16}}
\newlabel{fig:fig16-map-newark}{{16}{29}{Three ethnic groups in Newark (1880 US Census)}{figure.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Decision tree with orthogonal partitions for spatial classification, Newark ethnic groups}}{30}{figure.17}}
\newlabel{fig:fig17-tree-orthogonal-newark}{{17}{30}{Decision tree with orthogonal partitions for spatial classification, Newark ethnic groups}{figure.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Ethnic neighborhoods in Newark, 1880, using orthogonal partitions}}{31}{figure.18}}
\newlabel{fig:fig18-map-orthogonal-newark}{{18}{31}{Ethnic neighborhoods in Newark, 1880, using orthogonal partitions}{figure.18}{}}
\@writefile{toc}{\contentsline {subsection}{6.2 Regression Example: Spatial Market Segmentation}{31}{section*.10}}
\newlabel{regression-example-spatial-market-segmentation}{{}{31}{6.2 Regression Example: Spatial Market Segmentation}{section*.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Decision tree with non-orthogonal/non-linear partitions for spatial classification, Newark ethnic groups}}{32}{figure.19}}
\newlabel{fig:fig19-tree-basis-newark}{{19}{32}{Decision tree with non-orthogonal/non-linear partitions for spatial classification, Newark ethnic groups}{figure.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Ethnic neighborhoods in Newark, 1880, using non-orthogonal partitions}}{33}{figure.20}}
\newlabel{fig:fig20-map-basis-newark}{{20}{33}{Ethnic neighborhoods in Newark, 1880, using non-orthogonal partitions}{figure.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Land prices in Sapporo (log)}}{34}{figure.21}}
\newlabel{fig:fig21-map-sapporo}{{21}{34}{Land prices in Sapporo (log)}{figure.21}{}}
\@writefile{toc}{\contentsline {subsection}{6.3 Regression Example: Voter Turnout}{34}{section*.11}}
\newlabel{regression-example-voter-turnout}{{}{34}{6.3 Regression Example: Voter Turnout}{section*.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Decision tree with orthogonal partitions for submarket identification, Sapporo land prices}}{35}{figure.22}}
\newlabel{fig:fig22-tree-orthogonal-sapporo}{{22}{35}{Decision tree with orthogonal partitions for submarket identification, Sapporo land prices}{figure.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Spatial land price submarkets in Sapporo using orthogonal partitions}}{36}{figure.23}}
\newlabel{fig:fig23-map-orthogonal-sapporo}{{23}{36}{Spatial land price submarkets in Sapporo using orthogonal partitions}{figure.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Decision tree with non-orthogonal/non-linear partitions for submarket identification, Sapporo land prices}}{37}{figure.24}}
\newlabel{fig:fig24-tree-basis-sapporo}{{24}{37}{Decision tree with non-orthogonal/non-linear partitions for submarket identification, Sapporo land prices}{figure.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces IBF-based non-orthogonal land price regions (log) in Sapporo}}{38}{figure.25}}
\newlabel{fig:fig25-map-basis-sapporo}{{25}{38}{IBF-based non-orthogonal land price regions (log) in Sapporo}{figure.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Decision tree with orthogonal partitions, Ontario voter turnout}}{39}{figure.26}}
\newlabel{fig:fig26-tree-orthogonal-election}{{26}{39}{Decision tree with orthogonal partitions, Ontario voter turnout}{figure.26}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Descriptive statistics for electoral districts in Ontario, 2018}}{40}{table.5}}
\newlabel{tab:descriptive-statistics-election}{{5}{40}{Descriptive statistics for electoral districts in Ontario, 2018}{table.5}{}}
\newlabel{tab:descriptive-statistics-election}{{5}{40}{Descriptive statistics for electoral districts in Ontario, 2018}{table.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Decision tree with non-orthogonal/non-linear partitions, Ontario voter turnout}}{41}{figure.27}}
\newlabel{fig:fig27-tree-basis-election}{{27}{41}{Decision tree with non-orthogonal/non-linear partitions, Ontario voter turnout}{figure.27}{}}
\@writefile{toc}{\contentsline {section}{7 Conclusions and Directions for Future Research}{41}{section*.12}}
\newlabel{conclusions-and-directions-for-future-research}{{}{41}{7 Conclusions and Directions for Future Research}{section*.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Decision charts for voter turnout}}{42}{figure.28}}
\newlabel{fig:fig28-election-decision-charts}{{28}{42}{Decision charts for voter turnout}{figure.28}{}}
\@writefile{toc}{\contentsline {section}{Acknowledgments}{43}{section*.13}}
\newlabel{acknowledgments}{{}{43}{Acknowledgments}{section*.13}{}}
\newlabel{references}{{}{43}{References}{section*.14}{}}
\@writefile{toc}{\contentsline {section}{References}{43}{section*.14}}
